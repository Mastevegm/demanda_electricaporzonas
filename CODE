import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import plotly.graph_objects as go

data_path = 'combined_ori_2020_to_april_2024.csv' ##Datos descargados por data scraping
historical_data = pd.read_csv(data_path, index_col='Timestamp', parse_dates=True)

historical_data = historical_data[['', ')', 'Intercambio neto entre G']]
historical_data.replace(['], np.nan, inplace=True)
imputer = SimpleImputer(strategy='mean')
historical_data = pd.DataFrame(imputer.fit_transform(historical_data), columns=historical_data.columns, index=historical_data.index)

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(historical_data)

def create_dataset(dataset, look_back=60):
    X, Y = [], []
    for i in range(len(dataset) - look_back):
        X.append(dataset[i:i + look_back, :])
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)

look_back = 60
X_train, y_train = create_dataset(scaled_data, look_back)

# modelo LSTM
model = Sequential([
    LSTM(100, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),
    Dropout(0.2),
    LSTM(100, return_sequences=False),
    Dense(1)
])
model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')

model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)

# Preparar los datos para mayo de 2024
may_data_path = 'Datos_ORI_2024.csv'
may_data = pd.read_csv(may_data_path, index_col='Timestamp', parse_dates=True)
may_data = may_data[may_data.index.month == 5][['Estimac', 'Gene)', 'I)']]
may_data.replace(['], np.nan, inplace=True)
may_data = pd.DataFrame(imputer.transform(), columns=may_data.columns, index=may_data.index)

may_scaled = scaler.transform(may_data)

# Crear secuencia
X_may, _ = create_dataset(np.vstack([scaled_data[-look_back:], may_scaled]), look_back)

predictions_scaled = model.predict(X_may)
predictions = scaler.inverse_transform(np.concatenate([pd, n), 2))], axis=1))[:, 0]

# Comparación con datos reales
real_demand_may = may_data['Estimacion de Demanda'].values[:len(predictions)]
r2_may = r2_score(real_demand_may, predictions)

fig = go.Figure()

fig.add_trace(go.Scatter(
    x=may_data.index[:len(predictions)],
    y=real_demand_may,
    mode='lines',
    name='Datos Reales Mayo 2024',
    line=dict(color='blue')
))

fig.add_trace(go.Scatter(
    x=may_data.index[:len(predictions)],
    y=predictions,
    mode='lines',
    name='Predicciones Mayo 2024',
    line=dict(color='red')
))

fig.update_layout(
    title='Predicciones vs Datos Reales para Mayo 2024',
    xaxis_title='Fecha',
    yaxis_title='Estimación de Demanda por Balance (MWh)',
    legend_title='Leyenda',
    template='plotly_white'
)

fig.show()

print(f"R² para el mes de mayo de 2024: {r2_may:.4f}")
